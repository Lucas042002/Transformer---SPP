# Transformer + SPP ğŸ¯

**SoluciÃ³n hÃ­brida del Strip Packing Problem usando Transformers y Aprendizaje por ImitaciÃ³n**

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

---

## ğŸ“‹ Tabla de Contenidos

- [Contexto](#contexto)
- [InstalaciÃ³n](#instalaciÃ³n)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [Modelos Pre-entrenados](#modelos-pre-entrenados)
- [GuÃ­a de Uso RÃ¡pido](#guÃ­a-de-uso-rÃ¡pido)
- [Manual Completo](#manual-completo)
- [Arquitectura del Modelo](#arquitectura-del-modelo)
- [Resultados](#resultados)
- [Referencias](#referencias)

---

## ğŸ¯ Contexto

Este proyecto aborda el **Strip Packing Problem (SPP)**, un problema NP-hard de optimizaciÃ³n combinatoria que consiste en empaquetar rectÃ¡ngulos de diferentes dimensiones en un contenedor de ancho fijo minimizando la altura total.

**CaracterÃ­sticas del problema:**
- âœ… Rotaciones de 90Â° permitidas
- âœ… DivisiÃ³n de espacios tipo guillotina
- âœ… Sin solapamiento entre rectÃ¡ngulos
- âœ… Benchmarks clÃ¡sicos de Hopper & Turton (1999)

**SoluciÃ³n propuesta:**
- ğŸ§  **Modelo Pointer Network** basado en Transformer que aprende del algoritmo heurÃ­stico HR
- âš¡ **8.5Ã— mÃ¡s rÃ¡pido** que HR manteniendo calidad competitiva (Gap 24.59%)
- ğŸ“ **Imitation Learning** supervisado con data augmentation
- ğŸ”„ **Arquitectura hÃ­brida** que combina aprendizaje profundo con heurÃ­sticas clÃ¡sicas

---

## ğŸš€ InstalaciÃ³n

### **Requisitos del Sistema**
- Python 3.10 o superior
- GPU NVIDIA (opcional, recomendado para entrenamiento)
- 8GB RAM mÃ­nimo (16GB recomendado)

### **1. Clonar el repositorio**
```bash
git clone https://github.com/Lucas042002/Transformer---SPP.git
cd Transformer---SPP
```

### **2. Crear entorno virtual (recomendado)**
```bash
# Con venv
python -m venv venv

# Activar entorno
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate
```

### **3. Instalar dependencias**
```bash
pip install -r requirements.txt
```

### **LibrerÃ­as principales requeridas:**

#### **Core (obligatorias)**
```bash
torch>=2.0.0              # Framework de deep learning
numpy>=1.24.0             # ComputaciÃ³n numÃ©rica
matplotlib>=3.7.0         # VisualizaciÃ³n
```

#### **Adicionales (opcionales pero recomendadas)**
```bash
pandas>=2.0.0             # AnÃ¡lisis de datos (para analisis_complejidad.py)
seaborn>=0.12.0           # VisualizaciÃ³n estadÃ­stica
scipy>=1.10.0             # Funciones cientÃ­ficas
tqdm>=4.65.0              # Barras de progreso
```

#### **InstalaciÃ³n rÃ¡pida completa:**
```bash
pip install torch numpy matplotlib pandas seaborn scipy tqdm
```

#### **Para GPU (CUDA 11.8):**
```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

### **4. Verificar instalaciÃ³n**
```bash
python -c "import torch; print(f'PyTorch {torch.__version__}'); print(f'CUDA disponible: {torch.cuda.is_available()}')"
```

---

## ğŸ“ Estructura del Proyecto

```
Transformer---SPP/
â”‚
â”œâ”€â”€ ğŸ§  Core - Algoritmos y Modelos
â”‚   â”œâ”€â”€ hr_algorithm.py           # Algoritmo HeurÃ­stico Recursivo (HR) + generaciÃ³n de datos
â”‚   â”œâ”€â”€ hr_pointer.py             # VersiÃ³n hÃ­brida HR + Pointer Model
â”‚   â”œâ”€â”€ pointer_model.py          # Arquitectura Transformer (Encoder-Decoder)
â”‚   â”œâ”€â”€ pointer_training.py       # Pipeline de entrenamiento (Imitation Learning)
â”‚   â””â”€â”€ main.py                   # Script principal (entrenar/testear/visualizar)
â”‚
â”œâ”€â”€ ğŸ§ª Testing y AnÃ¡lisis
â”‚   â”œâ”€â”€ test_pointer.py           # Suite de testing con comparaciones
â”‚   â”œâ”€â”€ analisis_complejidad.py   # AnÃ¡lisis de complejidad temporal/espacial
â”‚   â”œâ”€â”€ greedy_algorithms.py      # Algoritmos baseline (FFDH, BFDH, BL, NF)
â”‚   â””â”€â”€ run_pointer.py            # Script rÃ¡pido de prueba
â”‚
â”œâ”€â”€ ğŸ¨ VisualizaciÃ³n y DocumentaciÃ³n
â”‚   â”œâ”€â”€ GUIA_TESTING.md           # GuÃ­a completa de testing
â”‚   â”œâ”€â”€ VISUALIZACION_TESTING.md  # DocumentaciÃ³n de visualizaciÃ³n
â”‚   â””â”€â”€ README.md                 # Este archivo
â”‚
â”œâ”€â”€ ğŸ“Š Datos y ConfiguraciÃ³n
â”‚   â”œâ”€â”€ generator.py              # Generador de problemas sintÃ©ticos
â”‚   â”œâ”€â”€ categories.py             # DefiniciÃ³n de categorÃ­as C1-C7
â”‚   â”œâ”€â”€ states.py                 # CodificaciÃ³n de features (10+19 dims)
â”‚   â”œâ”€â”€ tests/                    # Instancias benchmark (c1p1.txt, c2p1.txt, ...)
â”‚   â””â”€â”€ strip1.txt                # DescripciÃ³n de benchmarks originales
â”‚
â”œâ”€â”€ ğŸ¤– Modelos Pre-entrenados (4 modelos)
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ pointer_c1_L4_H8_acc8212.pth    # Modelo C1 (82.12% accuracy)
â”‚       â”œâ”€â”€ pointer_c2_L4_H8_acc8155.pth    # Modelo C2 (81.55% accuracy)
â”‚       â”œâ”€â”€ pointer_c3_L4_H8_acc7616.pth    # Modelo C3 (76.16% accuracy)
â”‚       â””â”€â”€ pointer_c4_L4_H8_acc7497.pth    # Modelo C4 (74.97% accuracy)
â”‚
â””â”€â”€ ğŸ“ˆ Resultados (generados automÃ¡ticamente)
    â””â”€â”€ img/
        â”œâ”€â”€ complexity_analysis/       # AnÃ¡lisis de complejidad
        â”‚   â”œâ”€â”€ tabla_C1.csv
        â”‚   â”œâ”€â”€ tabla_C2.csv
        â”‚   â”œâ”€â”€ mejores_C1/            # Mejores casos por categorÃ­a
        â”‚   â””â”€â”€ ...
        â””â”€â”€ *.png                      # GrÃ¡ficos de entrenamiento
```

---

## ğŸ¤– Modelos Pre-entrenados

El repositorio incluye **4 modelos entrenados** listos para usar:

| CategorÃ­a | Archivo | Accuracy | N RectÃ¡ngulos | TamaÃ±o |
|-----------|---------|----------|---------------|--------|
| **C1** | `pointer_c1_L4_H8_acc8212.pth` | 82.12% | 17 | ~20MB |
| **C2** | `pointer_c2_L4_H8_acc8155.pth` | 81.55% | 25 | ~20MB |
| **C3** | `pointer_c3_L4_H8_acc7616.pth` | 76.16% | 29 | ~20MB |
| **C4** | `pointer_c4_L4_H8_acc7497.pth` | 74.97% | 49 | ~20MB |

**HiperparÃ¡metros comunes:**
- ğŸ”¢ `d_model=256` (dimensiÃ³n del modelo)
- ğŸ§± `num_enc_layers=4` (capas del encoder)
- ğŸ‘ï¸ `num_heads=8` (attention heads)
- ğŸ”„ `d_ff=512` (feed-forward hidden dim)
- ğŸ“¦ Entrenados con 500 problemas base Ã— 3 (augmentation) = 1500 trayectorias

**Uso rÃ¡pido:**
```bash
# Testear modelo C1 pre-entrenado con 50 problemas
python main.py C1 test models/pointer_c1_L4_H8_acc8212.pth 50

# Visualizar casos extremos (mejores/peores)
python main.py C2 best-worst models/pointer_c2_L4_H8_acc8155.pth 30
```

---

## âš¡ GuÃ­a de Uso RÃ¡pido

### **ğŸ¯ Modo 1: Usar modelos pre-entrenados (Recomendado)**

```bash
# Testear modelo C1 con 50 problemas
python main.py C1 test models/pointer_c1_L4_H8_acc8212.pth 50

# Comparar con todos los algoritmos (HR, FFDH, BFDH, etc.)
python main.py C2 compare models/pointer_c2_L4_H8_acc8155.pth 30

# Visualizar problema individual (Pointer vs HR)
python main.py C3 visual models/pointer_c3_L4_H8_acc7616.pth

# Analizar mejores y peores casos
python main.py C4 best-worst models/pointer_c4_L4_H8_acc7497.pth 20
```

### **ğŸ”§ Modo 2: Entrenar nuevo modelo**

```bash
# Entrenar modelo para categorÃ­a C1 (usa configuraciÃ³n por defecto)
python main.py C1

# Entrenar para otra categorÃ­a
python main.py C3
```

**ConfiguraciÃ³n de entrenamiento (en `main.py`):**
- ğŸ“¦ 500 problemas base Ã— 3 (augmentation) = 1500 trayectorias
- ğŸ”„ 200 Ã©pocas con early stopping (paciencia 40)
- ğŸ“Š Batch size: 16
- ğŸ“ Learning rate: 1e-4 (AdamW)
- â±ï¸ Tiempo aproximado: 2-4 horas (GPU) / 8-12 horas (CPU)

### **ğŸ“Š Modo 3: AnÃ¡lisis de complejidad completo**

```bash
# Analizar todas las categorÃ­as con 500 problemas cada una
python main.py complexity C1 C2 C3 C4 500
```

Genera:
- âœ… Tablas CSV con mÃ©tricas (tiempo, memoria, altura, gaps)
- âœ… Boxplots comparativos
- âœ… IdentificaciÃ³n de mejores/peores casos
- âœ… AnÃ¡lisis de superioridad Pointer vs HR

---

## ğŸ“š Manual Completo

### **Comandos disponibles**

#### **1. Entrenamiento**
```bash
python main.py <CATEGORIA>
```
- `<CATEGORIA>`: C1, C2, C3, C4, C5, C6, C7
- Entrena un nuevo modelo desde cero
- Guarda automÃ¡ticamente en `models/pointer_<cat>_L<layers>_H<heads>_acc<accuracy>.pth`
- Genera grÃ¡ficas de entrenamiento en `img/`

**Ejemplo:**
```bash
python main.py C1
# Output: models/pointer_c1_L4_H8_acc8212.pth
#         img/pointer_c1_L4_H8_acc8212.png
```

---

#### **2. Testing**
```bash
python main.py <CATEGORIA> test [<MODELO_PATH>] [<N_PROBLEMAS>]
```
- Sin argumentos: usa Ãºltimo modelo entrenado con 10 problemas
- `<MODELO_PATH>`: ruta al archivo .pth especÃ­fico
- `<N_PROBLEMAS>`: cantidad de problemas a evaluar

**Ejemplos:**
```bash
# Testear Ãºltimo modelo C1 con 10 problemas
python main.py C1 test

# Testear modelo especÃ­fico con 50 problemas
python main.py C2 test models/pointer_c2_L4_H8_acc8155.pth 50

# EvaluaciÃ³n exhaustiva (100 problemas)
python main.py C3 test models/pointer_c3_L4_H8_acc7616.pth 100
```

**Output:**
```
EstadÃ­sticas del Pointer Model:
  Problemas evaluados: 50
  Altura promedio: 45.32
  Altura mÃ­nima: 32
  Altura mÃ¡xima: 67
  Desv. estÃ¡ndar: 8.45
  
ComparaciÃ³n vs HR:
  Casos superiores: 3 (6.0%)
  Casos iguales: 5 (10.0%)
  Casos inferiores: 42 (84.0%)
  Gap promedio vs HR: 23.45%
```

---

#### **3. ComparaciÃ³n completa**
```bash
python main.py <CATEGORIA> compare [<MODELO_PATH>] [<N_PROBLEMAS>]
```
Compara el Pointer Model con **todos los algoritmos baseline**:
- HR (Heuristic Recursive)
- FFDH (First Fit Decreasing Height)
- BFDH (Best Fit Decreasing Height)
- Next Fit
- Bottom-Left

**Ejemplo:**
```bash
python main.py C1 compare models/pointer_c1_L4_H8_acc8212.pth 30
```

**Output:**
```
Resultados Comparativos (30 problemas):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Algoritmo   â”‚ Altura   â”‚ Tiempo   â”‚ Gap HR   â”‚ Gap Href   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ HR          â”‚ 35.20    â”‚ 245.3ms  â”‚ 0.00%    â”‚ 12.45%     â”‚
â”‚ Pointer     â”‚ 43.87    â”‚ 28.5ms   â”‚ 24.63%   â”‚ 39.89%     â”‚
â”‚ FFDH        â”‚ 45.12    â”‚ 3.2ms    â”‚ 28.18%   â”‚ 44.00%     â”‚
â”‚ BFDH        â”‚ 45.01    â”‚ 3.5ms    â”‚ 27.86%   â”‚ 43.65%     â”‚
â”‚ Bottom-Left â”‚ 39.85    â”‚ 15.7ms   â”‚ 13.21%   â”‚ 27.20%     â”‚
â”‚ Next Fit    â”‚ 58.34    â”‚ 1.8ms    â”‚ 65.68%   â”‚ 86.30%     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Speedup Pointer vs HR: 8.6Ã—
```

---

#### **4. VisualizaciÃ³n interactiva**
```bash
python main.py <CATEGORIA> visual [<MODELO_PATH>]
```
Visualiza un problema aleatorio con comparaciÃ³n lado a lado Pointer vs HR.

**Ejemplo:**
```bash
python main.py C2 visual models/pointer_c2_L4_H8_acc8155.pth
```

**Muestra:**
- ğŸ“Š GrÃ¡fico comparativo (Pointer a la izquierda, HR a la derecha)
- ğŸ“ Altura de cada soluciÃ³n con lÃ­nea roja en Href
- ğŸ¨ Colores Ãºnicos por rectÃ¡ngulo
- ğŸ“ˆ Diferencia absoluta y porcentual

---

#### **5. AnÃ¡lisis de casos extremos**
```bash
python main.py <CATEGORIA> best-worst [<MODELO_PATH>] [<N_PROBLEMAS>]
```
Identifica y visualiza los **3 mejores** y **3 peores** casos del modelo.

**Ejemplo:**
```bash
python main.py C3 best-worst models/pointer_c3_L4_H8_acc7616.pth 50
```

**Output:**
```
Analizando 50 problemas...

ğŸ† TOP 3 MEJORES CASOS (Pointer supera a HR):
  #1: Problema 12 â†’ Pointer: 45, HR: 48 (diferencia: -3, -6.25%)
  #2: Problema 37 â†’ Pointer: 52, HR: 54 (diferencia: -2, -3.70%)
  #3: Problema 8  â†’ Pointer: 38, HR: 39 (diferencia: -1, -2.56%)

âš ï¸ TOP 3 PEORES CASOS (Pointer muy inferior a HR):
  #1: Problema 23 â†’ Pointer: 87, HR: 45 (diferencia: +42, +93.33%)
  #2: Problema 41 â†’ Pointer: 72, HR: 48 (diferencia: +24, +50.00%)
  #3: Problema 15 â†’ Pointer: 65, HR: 47 (diferencia: +18, +38.30%)

[Se generan 6 visualizaciones comparativas]
```

---

#### **6. AnÃ¡lisis de complejidad completo**
```bash
python main.py complexity <CAT1> <CAT2> ... <N_PROBLEMAS>
```
Ejecuta anÃ¡lisis exhaustivo en mÃºltiples categorÃ­as simultÃ¡neamente.

**Ejemplo:**
```bash
python main.py complexity C1 C2 C3 C4 500
```

**Genera:**
1. **Tablas CSV** (`img/complexity_analysis/tabla_C1.csv`, etc.)
   - Tiempo (ms)
   - Memoria (MB)
   - Altura final
   - Gap vs Href
   - Gap vs HR

2. **Tabla unificada** (`tabla_unificada.csv`) con mÃ©tricas globales

3. **Archivos de mejores casos** (`img/complexity_analysis/mejores_C1/`)

4. **Boxplots comparativos** por algoritmo y categorÃ­a

**Tiempo estimado:** 2-4 horas para 500 problemas Ã— 4 categorÃ­as

---

### **PersonalizaciÃ³n avanzada**

#### **Modificar hiperparÃ¡metros de entrenamiento**
Editar `main.py` lÃ­neas 280-295:

```python
NUM_PROBLEMAS = 500              # Problemas base
BATCH_SIZE = 16                  # TamaÃ±o de batch
EPOCHS = 200                     # Ã‰pocas mÃ¡ximas
NUM_ENC_LAYERS = 4               # Capas del encoder
NUM_HEADS = 8                    # Attention heads
LEARNING_RATE = 1e-4             # Learning rate
EARLY_STOPPING_PATIENCE = 40     # Paciencia early stopping
augment_permutations=2           # Data augmentation (Ã—3 datos)
```

#### **Modificar dimensiones del modelo**
Editar `main.py` lÃ­nea 335:

```python
model = SPPPointerModel(
    d_model=256,           # DimensiÃ³n embeddings
    rect_feat_dim=10,      # Features rectÃ¡ngulos
    space_feat_dim=19,     # Features espacios
    num_enc_layers=4,      # Capas encoder
    num_heads=8,           # Attention heads
    d_ff=512,              # FFN hidden dim
    dropout=0.1,           # Dropout rate
    max_steps=N            # MÃ¡ximo pasos
)
```

---

### **SoluciÃ³n de problemas comunes**

#### **Error: "CUDA out of memory"**
```bash
# Reducir batch size en main.py
BATCH_SIZE = 8  # o menor
```

#### **Error: "libiomp5md.dll duplicado" (Windows)**
Ya estÃ¡ solucionado en el cÃ³digo:
```python
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'
```

#### **Entrenamiento muy lento (CPU)**
```bash
# Reducir problemas y Ã©pocas para prueba rÃ¡pida
NUM_PROBLEMAS = 100
EPOCHS = 50
```

#### **Modelos no encontrados**
```bash
# Verificar que exista la carpeta models/
ls models/

# Si no existe, crearla:
mkdir models
```

---

## ğŸ§  Arquitectura del Modelo

### **Pointer Network basado en Transformer**

El modelo aprende a resolver el SPP mediante **Imitation Learning**, imitando las decisiones del algoritmo HR experto.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INPUT STAGE                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  RectÃ¡ngulos (NÃ—10)         Espacio Activo (19)        â”‚
â”‚  â€¢ Altura, ancho            â€¢ PosiciÃ³n (x, y)           â”‚
â”‚  â€¢ Ãrea                     â€¢ Dimensiones (w, h)        â”‚
â”‚  â€¢ Aspect ratio             â€¢ UtilizaciÃ³n potencial     â”‚
â”‚  â€¢ Compactness              â€¢ FragmentaciÃ³n             â”‚
â”‚  â€¢ CategorÃ­a tamaÃ±o         â€¢ Compatibilidad (8 dims)   â”‚
â”‚  â€¢ Ranking Ã¡rea             â€¢ Fit quality               â”‚
â”‚  â€¢ Densidad                 â€¢ Altura actual             â”‚
â”‚  â€¢ ... (10 features)        â€¢ ... (19 features)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ENCODER (Transformer, L=4)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  RectEncoder:                                           â”‚
â”‚  â€¢ ProyecciÃ³n lineal: 10 â†’ d_model (256)                â”‚
â”‚  â€¢ 4 capas TransformerEncoder                           â”‚
â”‚  â€¢ Multi-head attention (8 heads)                       â”‚
â”‚  â€¢ Feed-forward (d_ff=512)                              â”‚
â”‚  â€¢ Dropout (0.1)                                        â”‚
â”‚                                                         â”‚
â”‚  Output: Rect Embeddings (N Ã— 256) [CACHEADO]          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           DECODER (por cada paso t=1...N)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. SpaceEncoder:                                       â”‚
â”‚     space_feat (19) â†’ space_emb (256)                   â”‚
â”‚                                                         â”‚
â”‚  2. Global Context (dinÃ¡mico):                          â”‚
â”‚     global_ctx = MeanPool(RectEnc[mask])                â”‚
â”‚                                                         â”‚
â”‚  3. StepEmbedding:                                      â”‚
â”‚     step_emb = Embedding(t)                             â”‚
â”‚                                                         â”‚
â”‚  4. QueryBuilder:                                       â”‚
â”‚     query = FFN([space_emb || global_ctx || step_emb])  â”‚
â”‚                                                         â”‚
â”‚  5. PointerAttention:                                   â”‚
â”‚     scores = (query Â· RectEnc^T) / âˆšd                   â”‚
â”‚     scores[~mask] = -âˆ                                  â”‚
â”‚     probs = softmax(scores)                             â”‚
â”‚                                                         â”‚
â”‚  Output: Probabilidades sobre rectÃ¡ngulos (N)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  TRAINING (Supervised)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Loss: Cross-Entropy (con weighted loss opcional)       â”‚
â”‚  L = (1/T) Î£ w_t Â· (-log(p_t[y_t]))                     â”‚
â”‚  donde w_t âˆˆ [1.0, 2.0] (pasos finales pesan mÃ¡s)       â”‚
â”‚                                                         â”‚
â”‚  Optimizer: AdamW (lr=1e-4, weight_decay=1e-4)          â”‚
â”‚  Data Augmentation: 2 permutaciones Ã— problema (Ã—3)     â”‚
â”‚  Early Stopping: Paciencia 40 Ã©pocas                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Complejidad Computacional**

| Componente | Complejidad | ExplicaciÃ³n |
|------------|-------------|-------------|
| **Encoder** (1 vez) | O(LÂ·NÂ²Â·d) | L=4 capas, self-attention cuadrÃ¡tica |
| **Decoder** (N pasos) | O(NÂ²Â·d + NÂ·dÂ²) | AtenciÃ³n + FFN |
| **Total** | **O(LÂ·NÂ²Â·d + NÂ·dÂ²)** | Dominado por self-attention |

**ComparaciÃ³n:**
- **HR:** O(NÂ²Â·M) donde M = espacios activos (bÃºsqueda exhaustiva)
- **Pointer:** O(NÂ²Â·d) con d=256 (paralelizable en GPU)
- **Speedup observado:** **8.5Ã— en promedio**, hasta 16.4Ã— en C4

---

## ğŸ“Š Resultados Experimentales

### **MÃ©tricas Generales (2000 problemas de test)**

| MÃ©trica | Valor | Observaciones |
|---------|-------|---------------|
| **Accuracy promedio** | 78.85% | Decisiones correctas vs HR |
| **Gap vs HR** | 24.59% | Altura promedio 24.59% mayor que HR |
| **Gap vs Href** | 57.63% | Respecto a altura de referencia Ã³ptima |
| **Tiempo promedio** | 28.43 ms | vs 241.09 ms de HR (8.5Ã— mÃ¡s rÃ¡pido) |
| **Casos superiores** | 52 (2.6%) | Pointer encuentra mejor soluciÃ³n que HR |
| **Casos iguales** | 166 (8.3%) | Pointer iguala a HR |
| **Casos inferiores** | 1782 (89.1%) | Pointer inferior a HR |

### **DesempeÃ±o por CategorÃ­a**

| CategorÃ­a | N Rects | Accuracy | Gap HR | Tiempo Pointer | Speedup |
|-----------|---------|----------|--------|----------------|---------|
| **C1** | 17 | 82.12% | 18.45% | 15.2 ms | 7.8Ã— |
| **C2** | 25 | 81.55% | 22.67% | 22.5 ms | 8.2Ã— |
| **C3** | 29 | 76.16% | 27.83% | 28.9 ms | 9.1Ã— |
| **C4** | 49 | 74.97% | 29.41% | 47.3 ms | 16.4Ã— |

### **ComparaciÃ³n con Algoritmos Baseline**

```
Ranking por Altura Final (menor = mejor):
1. HR (Heuristic Recursion)     â†’ Gap: 0.00%   â­ Referencia
2. Bottom-Left                  â†’ Gap: 13.43%  ğŸ¥ˆ Segundo mejor
3. Pointer Model                â†’ Gap: 24.59%  ğŸ¥‰ Tercero (pero 8.5Ã— mÃ¡s rÃ¡pido)
4. BFDH                         â†’ Gap: 28.40%
5. FFDH                         â†’ Gap: 28.50%
6. Next Fit                     â†’ Gap: 76.89%

Ranking por Tiempo (menor = mejor):
1. Next Fit        â†’ 2.1 ms   âš¡ MÃ¡s rÃ¡pido (pero peor calidad)
2. FFDH            â†’ 3.8 ms
3. BFDH            â†’ 4.2 ms
4. Pointer Model   â†’ 28.4 ms  ğŸ¯ Balance calidad/velocidad
5. Bottom-Left     â†’ 156.7 ms
6. HR              â†’ 241.1 ms
```

### **AnÃ¡lisis CrÃ­tico**

**Fortalezas identificadas:**
- âœ… Speedup consistente (8.5Ã—) sin hardware especializado
- âœ… Ocasionalmente descubre soluciones superiores (2.6% casos)
- âœ… Iguala a HR en 8.3% de instancias (estrategias equivalentes)
- âœ… Mejor que algoritmos greedy clÃ¡sicos (FFDH, BFDH)

**Limitaciones observadas:**
- âš ï¸ FragmentaciÃ³n vertical excesiva en casos complejos
- âš ï¸ Dificultad con rectÃ¡ngulos heterogÃ©neos (C3, C4)
- âš ï¸ Decisiones tempranas subÃ³ptimas propagan errores
- âš ï¸ RepresentaciÃ³n vectorial fija (d=256) limita captura espacial

**Mejoras futuras propuestas:**
- ğŸ”® Graph Neural Networks para relaciones espaciales explÃ­citas
- ğŸ”® Reinforcement Learning con reward shaping directo
- ğŸ”® Beam search con k candidatos (exploraciÃ³n limitada)
- ğŸ”® Refinamiento post-procesamiento con movimientos locales

Ver documentaciÃ³n completa en la tesis para anÃ¡lisis detallado.

---

## ğŸ“– DocumentaciÃ³n Adicional

- ğŸ“˜ **GUIA_TESTING.md** - GuÃ­a exhaustiva de testing y evaluaciÃ³n
- ğŸ¨ **VISUALIZACION_TESTING.md** - Sistema de visualizaciÃ³n completa
- ğŸ“„ **Tesis completa** - Fundamentos teÃ³ricos y anÃ¡lisis experimental

---

## ğŸ¤ Contribuciones

Este proyecto es parte de una tesis de pregrado. Para consultas o colaboraciones:

- ğŸ“§ Email: lucas.sepulveda@example.com
- ğŸ”— GitHub: [@Lucas042002](https://github.com/Lucas042002)

---

## ğŸ“š Referencias

1. **Hopper, E., & Turton, B. C. H. (1999).** "An Empirical Investigation of Meta-heuristic and Heuristic Algorithms for a 2D Packing Problem." *European Journal of Operations Research*, 113(3), 503-521.

2. **Vaswani, A., et al. (2017).** "Attention is All You Need." *Advances in Neural Information Processing Systems (NeurIPS)*, 30.

3. **Vinyals, O., Fortunato, M., & Jaitly, N. (2015).** "Pointer Networks." *Advances in Neural Information Processing Systems (NeurIPS)*, 28.

4. **Bello, I., et al. (2016).** "Neural Combinatorial Optimization with Reinforcement Learning." *arXiv preprint arXiv:1611.09940*.

---

## â­ Agradecimientos

- Benchmarks basados en el trabajo de Hopper & Turton (1999)
- Arquitectura inspirada en Pointer Networks (Vinyals et al., 2015) y Transformer (Vaswani et al., 2017)
- Framework PyTorch para implementaciÃ³n eficiente del modelo
- Comunidad de investigaciÃ³n en optimizaciÃ³n combinatoria y deep learning

---

**Desarrollado como parte de tesis de pregrado en IngenierÃ­a Civil Informatica**

*Ãšltima actualizaciÃ³n: Noviembre 2025*